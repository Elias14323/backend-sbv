# Backend Python (FastAPI + Celery) ‚Äî Plan ex√©cutable

> **üìÖ Derni√®re mise √† jour** : 1er Octobre 2025  
> **üöÄ √âtat** : MVP Phase 1-3 compl√©t√©s (Ingestion + IA + Temps r√©el)  
> **üìä Progression** : √âtapes 0-7 + 14 termin√©es (voir ¬ß17)  
> **üîó Repo GitHub** : https://github.com/Elias14323/backend-sbv

## ‚úÖ Accomplissements r√©cents

### Phase 1 : Pipeline de base (30/09/2025)
- ‚úÖ Pipeline d'ingestion RSS complet op√©rationnel
- ‚úÖ 19 articles ing√©r√©s, 16 embeddings, 3 clusters cr√©√©s
- ‚úÖ API `/api/v1/topics` fonctionnelle
- ‚úÖ Fixes majeurs : Trafilatura 2.0, Mistral API, pgvector, event loops
- ‚úÖ Repo GitHub initialis√© et push√©

### Phase 2 : R√©sum√©s et Analyse IA (30/09/2025 soir)
- ‚úÖ Table `cluster_summaries` avec versioning cr√©√©e
- ‚úÖ Service de r√©sum√© avec Mistral chat completion impl√©ment√©
- ‚úÖ T√¢che Celery `summarize_cluster` avec d√©clenchement automatique
- ‚úÖ API enrichie avec r√©sum√©s, bias analysis et timeline
- ‚úÖ Test r√©ussi : r√©sum√© de 7.4k caract√®res g√©n√©r√© pour cluster de 14 articles

### Phase 3 : D√©tection d'√©v√©nements et Streaming temps r√©el (1er/10/2025)
- ‚úÖ Tables `trend_metrics` et `events` avec mod√®les cr√©√©s
- ‚úÖ Service trending : calcul de v√©locit√©, acc√©l√©ration, nouveaut√©, d√©tection d'anomalies
- ‚úÖ T√¢che Celery `calculate_trends` (analyse clusters actifs 24h)
- ‚úÖ T√¢che Celery `detect_events` (d√©tection de pics, s√©v√©rit√©s low/medium/high/critical)
- ‚úÖ Endpoint SSE `/api/v1/stream/events` avec Redis Pub/Sub
- ‚úÖ Test end-to-end : client SSE re√ßoit √©v√©nements en temps r√©el via Redis
- ‚úÖ Backend v√©ritablement **vivant** : peut pousser breaking news instantan√©ment

---

## 0) Objectifs

- [ ] Ingestion multi-sources (RSS, APIs sociales, scraping si autoris√©)
- [ ] Regroupement par **sujet** (clustering sur embeddings)
- [ ] **D√©biaisage**: r√©sum√© factuel + analyse des angles/biais + timeline sourc√©e
- [ ] API pour Flutter (+ temps r√©el)
- [ ] Base: **Supabase Postgres** (pgvector) ‚Äî pas de Supabase Functions
- [ ] **Mistral** pour embeddings + g√©n√©ration

## 0bis) Fonctionnalit√©s n√©cessaires (d√©taill√©es)

**Ingestion (pragmatique)**

- [ ] **MVP** : **RSS/Atom + APIs officielles** uniquement (pas de crawler autonome).
- [ ] **Phase 2** : + **sitemaps** et **scrapers cibl√©s** (quelques sources prioritaires sans bon flux).
- [ ] **Phase 3** : crawler complet (frontier, d√©couverte de liens) si ROI av√©r√©.

**Normalisation & qualit√©**

- [ ] Canonisation d‚ÄôURL, extraction de texte, d√©tection de langue, timezone, auteur/source, estimation de qualit√© (bruit, longueur utile, duplication).
- [ ] D√©duplication (hash exact + simhash) et marquage.

**Vectorisation & recherche**

- [ ] Embeddings multilingues, stockage vecteur, recherche s√©mantique (kNN), plein‚Äëtexte tol√©rant aux fautes.

**Clustering par sujet**

- [ ] Attribution en flux (seuil de similarit√© + fen√™tre glissante), fusion/scission p√©riodiques, √©tiquetage automatique.

**R√©sum√© & ‚Äúbias breakdown‚Äù**

- [ ] R√©sum√© factuel multi‚Äësources, angles/biais, accords/d√©saccords, timeline dat√©e, lacunes, r√©f√©rences.

**D√©tection d‚Äô√©v√®nements & notifications**

- [ ] Volume/v√©locit√©/acc√©l√©ration/novelty/locality + corroboration multi‚Äësources.
- [ ] R√®gles d‚Äôalerte (entit√©s, mots‚Äëcl√©s, zones, s√©v√©rit√©, quiet hours), push FCM, d√©duplication.

**Personnalisation & UX**

- [ ] Abonnements (entit√©/sujet/mot‚Äëcl√©/lieu), favoris, feedback, pr√©f√©rences de langue.

**Administration & observabilit√©**

- [ ] Dashboards sources/queues, co√ªts LLM, m√©triques SLO, traces/logs, reprocessing.

**S√©curit√© & conformit√©**

- [ ] Auth, RBAC, RGPD (export/suppression), chiffrement, gestion secrets.

---

## 1) Stack de r√©f√©rence (Python-first)

- [x] **Python** 3.13 ‚úÖ
- [x] **FastAPI** (API HTTP + SSE/WebSocket) ‚úÖ 30/09/2025
- [x] **SQLAlchemy 2.0** (async) + **asyncpg** (PostgreSQL 14 local) + **Alembic** (migrations) ‚úÖ 30/09/2025
- [x] **Redis** (broker/queue) + **Celery** (workers + retries + DLQ) ‚úÖ 30/09/2025
- [ ] **Meilisearch** (recherche tol√©rante aux fautes)
- [x] **pgvector** (similarit√© via cosine dans Postgres) ‚úÖ 30/09/2025
- [x] **httpx** (async HTTP), **trafilatura 2.0** (extraction), **Playwright** (pages JS) ‚úÖ 30/09/2025
- [x] **langdetect** ou **fasttext-langdetect** (langue), **tldextract** (canonisation), **python-simhash** (near-duplicates) ‚úÖ 30/09/2025
- [ ] **prometheus-fastapi-instrumentator** (m√©triques), **structlog** (logs), **OpenTelemetry** (optionnel)

> Alternative queue: **Dramatiq** (Redis/Rabbit). Si vous voulez plus simple que Celery, Dramatiq est excellent.

---

## 2) Architecture & flux

```
[ingest] -> [normalize] -> [dedupe] -> [embed] -> [cluster] -> [summarize]
                              |              |               |
                            DB write       DB write        DB write
```

- [ ] Chaque √©tape = **job Celery** idempotent (cl√©: URL canonique).
- [ ] **Rate limiting** par domaine, **backoff** exponentiel, **DLQ** sur √©checs.
- [ ] **Fen√™tre glissante** 24‚Äì72h pour le clustering.

## 2bis) Structure de fonctionnement du backend (modules & responsabilit√©s)

- [ ] **API Gateway (FastAPI)** : endpoints publics (topics, recherche, sources, abonnements), SSE/WebSocket pour temps r√©el, auth.
- [ ] **Orchestrateur de jobs (Celery/Redis)** : planification, priorit√©s, retries, DLQ, idempotence.
- [ ] **Service Ingestion** : lecture RSS/APIs, d√©couverte via sitemaps/liens, alimentation de la frontier.
- [ ] **Service Fetch/Extract** : t√©l√©chargement (politeness), extraction texte/m√©tadonn√©es, normalisation.
- [ ] **Service D√©doublonnage** : hash exact, simhash, marquage et routage vers indexation si unique.
- [ ] **Service Embeddings** : appels LLM d‚Äôembedding, stockage pgvector, index kNN.
- [ ] **Service Clustering** : assignation en flux, fusion/scission p√©riodiques, √©tiquetage.
- [ ] **Service R√©sum√©/Biais** : agr√©gation multi‚Äësources, g√©n√©ration contr√¥l√©e, stockage markdown.
- [ ] **Service Recherche** : indexation Meilisearch, synonymes/stop‚Äëwords, filtres.
- [ ] **Service Tendance/√âv√®nements** : calcul m√©triques, bursts, corroboration.
- [ ] **Service Notifications** : appariement r√®gles, construction payload, envoi FCM/e‚Äëmail, journalisation.
- [ ] **Admin/Observabilit√©** : m√©triques, logs, traces, dashboards, outils de reprocessing.

---

## 2ter) Strat√©gie d‚Äôingestion par phases (pragmatique)

- [ ] **Phase 1 (MVP)** : **RSS/Atom + APIs** ‚Äî focus sur clustering, r√©sum√©s/biais, temps r√©el, recherche, notifs.
- [ ] **Phase 2** : **Sitemaps + scrapers cibl√©s** ‚Äî combler les sources prioritaires sans flux.
- [ ] **Phase 3** : **Crawler autonome** ‚Äî seulement si ROI/ressources, pour exhaustivit√©.

---

## 3) Sch√©ma Postgres (Supabase) ‚Äî **unifi√© v1**

> Objectif : coh√©rence, versionnement natif, A/B facile, extensible vers IA locale, **sans casser l‚ÄôAPI**.

### 3.1 Sources & sant√©

**‚úÖ Cr√©√©e (migration f73907598549)**

````sql
create table sources (
  id bigserial primary key,
  name text not null,
  url text not null unique,
  kind text check (kind in ('rss','site','social','api')) not null,
  country_code text,              -- ISO 3166-1 alpha-2 (pays d'immatriculation)
  lang_default text,              -- langue principale du m√©dia
  trust_tier text check (trust_tier in ('A','B','C')) default 'B',
  political_axis jsonb,           -- {"left_right": -1..+1, "auth_lib": -1..+1}
  scope text check (scope in ('local','regional','national','international')) default 'national',
  home_area_id bigint,            -- FK logique vers geo_areas (d√©fini en ¬ß3.13)
  last_fetch_at timestamptz,
  error_rate real default 0,
  created_at timestamptz default now()
);
```sql
create table sources (
  id bigserial primary key,
  name text not null,
  url text not null unique,
  kind text check (kind in ('rss','site','social','api')) not null,
  country_code text,              -- ISO 3166-1 alpha-2
  lang_default text,              -- langue principale du m√©dia
  trust_tier text check (trust_tier in ('A','B','C')) default 'B',
  political_axis jsonb,           -- ex: {"left_right": -0.3, "auth_lib": 0.1}
  topics jsonb,                   -- th√©matiques principales d√©clar√©es
  last_fetch_at timestamptz,
  error_rate real default 0,
  created_at timestamptz default now()
);
````

### 3.2 Articles & duplication

**‚úÖ Cr√©√©e (migration f73907598549)**

```sql
create table articles (
  id bigserial primary key,
  source_id bigint references sources(id) on delete cascade,
  url text unique,
  url_canonical text,
  title text,
  author text,
  lang text,
  published_at timestamptz,
  raw_html text,
  text_content text,
  hash_64 bytea,
  simhash_64 bigint,
  quality_score real,
  created_at timestamptz default now()
);

-- Liens de duplication
create table article_duplicates (
  article_id bigint references articles(id) on delete cascade,
  duplicate_of_id bigint references articles(id) on delete cascade,
  kind text check (kind in ('exact','near')) not null,
  distance int,                    -- hamming pour near dup
  primary key (article_id)
);
create index on articles (published_at desc);
create index on articles (url_canonical);
```

### 3.3 Embeddings **multi-espaces** (A/B pr√™t)

**‚úÖ Cr√©√©e (migration 22211ae2db72)** ‚Äî _Note: table nomm√©e `article_embeddings` au lieu de `article_embeddings_multi`_

```sql
create table embedding_spaces (
  id bigserial primary key,
  name text not null,
  provider text not null,    -- 'mistral','oss-local',...
  dims int not null,
  version text,
  notes text,
  created_at timestamptz default now(),
  unique(name, version)
);

create table article_embeddings_multi (
  space_id bigint references embedding_spaces(id),
  article_id bigint references articles(id) on delete cascade,
  embedding vector(1024),
  primary key (space_id, article_id)
);
create index article_embeddings_multi_vec on article_embeddings_multi using ivfflat (embedding vector_cosine_ops);
```

### 3.4 Clustering **versionn√© uniquement** + vues actives

**‚úÖ Cr√©√©e (migration 22211ae2db72)** ‚Äî _Note: tables nomm√©es `clusters`/`article_clusters` au lieu de `clusters_v`/`article_cluster_v`, vues pas encore cr√©√©es_

```sql
create table cluster_runs (
  id bigserial primary key,
  space_id bigint references embedding_spaces(id),
  algo text not null,                 -- 'threshold+communities','hdbscan', ...
  params jsonb not null,
  started_at timestamptz default now(),
  finished_at timestamptz,
  status text check (status in ('running','complete','failed')),
  is_active boolean default false,
  notes text
);

create table clusters_v (
  id bigserial primary key,
  run_id bigint references cluster_runs(id) on delete cascade,
  label text,
  window_start timestamptz,
  window_end timestamptz,
  created_at timestamptz default now()
);

create table article_cluster_v (
  run_id bigint references cluster_runs(id) on delete cascade,
  cluster_id bigint references clusters_v(id) on delete cascade,
  article_id bigint references articles(id) on delete cascade,
  similarity real,
  primary key (run_id, cluster_id, article_id)
);

create view v_clusters_active as
  select c.* from clusters_v c join cluster_runs r on r.id=c.run_id where r.is_active;
create view v_article_cluster_active as
  select ac.* from article_cluster_v ac join cluster_runs r on r.id=ac.run_id where r.is_active;
```

### 3.5 R√©sum√©s & biais **versionn√©s** + langue

**‚ùå Pas encore cr√©√©e**

```sql
create table cluster_summaries_v (
  run_id bigint references cluster_runs(id) on delete cascade,
  cluster_id bigint references clusters_v(id) on delete cascade,
  engine text not null,            -- 'mistral','local-llm'
  engine_version text,
  lang text not null default 'en', -- langue du rendu
  summary_md text,
  bias_md text,
  timeline_md text,
  sources jsonb,
  created_at timestamptz default now(),
  primary key (run_id, cluster_id, engine, engine_version, lang)
);
```

### 3.6 Entit√©s & g√©o (KG light)

```sql
create table entities (
  id bigserial primary key,
  kind text check (kind in ('person','org','place','event','other')),
  name text not null,
  aliases text[],
  external_ids jsonb,
  created_at timestamptz default now()
);

create table geo_areas (
  id bigserial primary key,
  kind text check (kind in ('country','admin1','admin2','city','custom_bbox')) not null,
  code text,                      -- ex: FR, FR-75, code INSEE, etc.
  name text not null,
  parent_id bigint references geo_areas(id),
  centroid geometry,              -- optionnel: PostGIS
  bbox geometry,                  -- optionnel: PostGIS
  population int
);

create table source_geo_coverage (
  source_id bigint references sources(id) on delete cascade,
  area_id bigint references geo_areas(id) on delete cascade,
  level text check (level in ('primary','secondary')) default 'primary',
  weight real default 1.0,
  primary key (source_id, area_id)
);

create table places (
  id bigserial primary key,
  toponym text,
  geonames_id bigint,
  osm_id text,
  centroid geometry,
  country_code text
);

create table article_entities (
  article_id bigint references articles(id) on delete cascade,
  entity_id bigint references entities(id) on delete cascade,
  salience real,
  spans jsonb,
  primary key (article_id, entity_id)
);

create table article_geo (
  article_id bigint primary key references articles(id) on delete cascade,
  area_id bigint references geo_areas(id),
  method text,                    -- 'ner','schema_org','source_default','url_path','tld'
  confidence real
);
```

**Remarques** : `sources.home_area_id` peut pointer vers un `geo_areas` (ville/r√©gion/pays) pour la racine g√©o du m√©dia.sql
create table entities (
id bigserial primary key,
kind text check (kind in ('person','org','place','event','other')),
name text not null,
aliases text[],
external_ids jsonb,             -- wikidata, isni, etc.
created_at timestamptz default now()
);

create table article_entities (
article_id bigint references articles(id) on delete cascade,
entity_id bigint references entities(id) on delete cascade,
salience real,
spans jsonb,                    -- offsets par langue
primary key (article_id, entity_id)
);

create table places (
id bigserial primary key,
toponym text,
geonames_id bigint,
osm_id text,
centroid geometry,              -- optionnel: PostGIS si activ√©
country_code text
);

````

### 3.7 √âv√®nements & tendances

**‚úÖ Cr√©√©es (migration 9897e6a21d7f)** ‚Äî 1er Octobre 2025

```sql
create table trend_metrics (
  ts timestamptz not null,
  cluster_id bigint references clusters_v(id) on delete cascade,
  run_id bigint references cluster_runs(id) on delete cascade,
  doc_count int,
  unique_sources int,
  velocity real,
  acceleration real,
  novelty real,
  locality real,                  -- 0..1 (proportion d'articles fortement localis√©s)
  primary key (ts, cluster_id, run_id)
);

create table cluster_locations (
  run_id bigint references cluster_runs(id) on delete cascade,
  cluster_id bigint references clusters_v(id) on delete cascade,
  area_id bigint references geo_areas(id) on delete cascade,
  weight real,                    -- importance dans le cluster
  primary key (run_id, cluster_id, area_id)
);

create table events (
  id bigserial primary key,
  run_id bigint references cluster_runs(id) on delete cascade,
  cluster_id bigint references clusters_v(id) on delete cascade,
  detected_at timestamptz not null default now(),
  score real not null,
  severity text check (severity in ('low','medium','high','critical')),
  label text,
  window_start timestamptz,
  window_end timestamptz
);
````

### 3.8 Notifications & pr√©f√©rences utilisateur

```sql
-- Supabase Auth g√®re les utilisateurs; profil local compl√©mentaire
create table user_profiles (
  user_id uuid primary key,             -- = auth.uid
  preferred_lang text default 'en',
  created_at timestamptz default now()
);

create table user_devices (
  id bigserial primary key,
  user_id uuid not null,
  fcm_token text not null,
  platform text check (platform in ('ios','android','web')) not null,
  created_at timestamptz default now()
);

create table subscriptions (
  id bigserial primary key,
  user_id uuid not null,
  kind text check (kind in ('entity','topic','keyword','location')) not null,
  value text not null,
  lang text,
  min_severity text default 'medium',
  quiet_hours int4range,
  created_at timestamptz default now()
);

create table notifications (
  id bigserial primary key,
  user_id uuid not null,
  event_id bigint references events(id) on delete cascade,
  title text,
  body text,
  sent_at timestamptz,
  dedupe_key text,
  channel text check (channel in ('push')) not null default 'push',
  status text check (status in ('scheduled','sent','failed')) not null default 'scheduled'
);
create unique index on notifications (user_id, dedupe_key);
```

### 3.9 S√©lection des sources par l‚Äôutilisateur & **bundles politiques/th√©matiques**

````sql
create table source_profiles (
  source_id bigint primary key references sources(id) on delete cascade,
  political_axis jsonb,           -- {left_right: -1..+1, auth_lib: -1..+1}
  tags text[]                     -- ex: ['investigation','opinion','public-broadcaster']
);

create table categories (
  id bigserial primary key,
  slug text unique not null,      -- ex: 'general','politics','sports','motorsports','tech','business','culture','science','health','local'
  name text not null,
  parent_id bigint references categories(id),
  description text
);

create table source_categories (
  source_id bigint references sources(id) on delete cascade,
  category_id bigint references categories(id) on delete cascade,
  primary key (source_id, category_id)
);

create table bundles (
  id bigserial primary key,
  name text not null,             -- ex: 'Gauche FR', 'Centre US', 'Conservateur UK', 'Sports FR'
  description text,
  axis_filter jsonb,              -- plage sur axes politique (optionnel)
  category_filter bigint,         -- FK vers categories (optionnel)
  area_filter bigint              -- FK vers geo_areas (optionnel)
);

create table bundle_sources (
  bundle_id bigint references bundles(id) on delete cascade,
  source_id bigint references sources(id) on delete cascade,
  primary key (bundle_id, source_id)
);

create table user_sources (
  user_id uuid not null,
  source_id bigint not null references sources(id) on delete cascade,
  primary key (user_id, source_id)
);

create table user_bundles (
  user_id uuid not null,
  bundle_id bigint not null references bundles(id) on delete cascade,
  primary key (user_id, bundle_id)
);
```sql
create table source_profiles (
  source_id bigint primary key references sources(id) on delete cascade,
  political_axis jsonb,           -- {left_right: -1..+1, auth_lib: -1..+1}
  tags text[]                     -- ex: ['investigation','opinion','public-broadcaster']
);

create table bundles (
  id bigserial primary key,
  name text not null,             -- ex: 'Gauche FR', 'Centre US', 'Conservateur UK'
  description text,
  axis_filter jsonb               -- plage sur axes politique
);

create table bundle_sources (
  bundle_id bigint references bundles(id) on delete cascade,
  source_id bigint references sources(id) on delete cascade,
  primary key (bundle_id, source_id)
);

create table user_sources (
  user_id uuid not null,
  source_id bigint not null references sources(id) on delete cascade,
  primary key (user_id, source_id)
);

create table user_bundles (
  user_id uuid not null,
  bundle_id bigint not null references bundles(id) on delete cascade,
  primary key (user_id, bundle_id)
);
````

### 3.10 Biais au **niveau article** (score & justification)

```sql
create table article_bias_labels (
  article_id bigint primary key references articles(id) on delete cascade,
  left_right real,                 -- -1 (gauche) ... +1 (droite)
  auth_lib real,                   -- -1 (libertaire) ... +1 (autoritaire)
  confidence real,                 -- 0..1
  cues jsonb,                      -- indices d√©tect√©s (lexique, cadrage, sources cit√©es)
  model text,                      -- moteur/heuristiques
  created_at timestamptz default now()
);
```

### 3.11 A/B tests & feature flags

```sql
create table feature_flags (
  key text primary key,
  value jsonb,
  description text
);

create table ab_tests (
  id bigserial primary key,
  name text,
  run_id bigint references cluster_runs(id),
  created_at timestamptz default now()
);

create table ab_buckets (
  test_id bigint references ab_tests(id) on delete cascade,
  user_id uuid,
  bucket text check (bucket in ('control','variant')),
  primary key (test_id, user_id)
);
```

### 3.12 Partitionnement & r√©tention (m√©tadonn√©es)

```sql
create table retention_policies (
  table_name text primary key,
  keep_days int not null,
  notes text
);
```

---

## 4) Dossiers (monorepo simple)

```
backend/
  app/
    api/
      __init__.py
      deps.py
      routes_topics.py
      routes_search.py
      routes_stream.py
    core/
      config.py
      logging.py
      db.py
      meili.py
      mistral.py
      rate_limit.py
    models/
      base.py
      article.py
      cluster.py
    services/
      ingest.py
      normalize.py
      dedupe.py
      embed.py
      clusterer.py
      summarize.py
    workers/
      celery_app.py
      tasks.py
  alembic/
  pyproject.toml
  docker/
    Dockerfile.api
    Dockerfile.worker
    docker-compose.yml
```

---

## 5) D√©pendances (liste, sans code)

- [ ] **Runtime** : Python ‚â• 3.13
- [ ] **API** : FastAPI, Uvicorn
- [ ] **DB/ORM** : SQLAlchemy 2.x (async), asyncpg, Alembic (migrations)
- [ ] **Queue** : Redis, Celery (ou Dramatiq en alternative)
- [ ] **HTTP & parsing** : httpx, trafilatura/readability‚Äëlxml, Playwright (pages dynamiques)
- [ ] **Langue & d√©doublonnage** : d√©tecteur de langue (langdetect/fastText), tldextract, simhash
- [ ] **Vecteurs & recherche** : pgvector (Postgres), Meilisearch
- [ ] **Observabilit√©** : structlog, Prometheus instrumentator, OpenTelemetry (optionnel)
- [ ] **S√©curit√©** : libs JWT/OAuth2, gestion secrets (Vault/SM) c√¥t√© infra

---

## 6) Configuration & secrets (principaux param√®tres)

- [ ] **DATABASE_URL / SYNC_DATABASE_URL** : connexions Postgres (async/sync) vers Supabase.
- [ ] **REDIS_URL** : broker/stockage √©tats de jobs.
- [ ] **MEILI_HOST / MEILI_KEY** : acc√®s Meilisearch.
- [ ] **MISTRAL_API_KEY** : cl√© API pour embeddings & g√©n√©ration.
- [ ] **CLUSTER_COSINE_THRESHOLD** : seuil de similarit√© (ex. 0,75‚Äì0,82 selon tuning).
- [ ] **CLUSTER_WINDOW_HOURS** : fen√™tre temporelle (ex. 24‚Äì72h) pour l‚Äôassignation.
- [ ] **CRAWL_BUDGETS** : quotas par domaine (req/min, connexions, plages).
- [ ] **ALERT_DEFAULTS** : seuils par d√©faut pour la d√©tection d‚Äô√©v√®nements/r√®gles.
- [ ] **TZ_DEFAULT** : Europe/Paris.

---

## 7) API ‚Äî sp√©cification (sans code)

**Endpoints principaux**

- [ ] `GET /topics` : liste pagin√©e des sujets de la **run active**; filtres: `category`, `area_id`, `country_code`, `scope`, `lang`, `bundle`, `since`.
- [x] `GET /topics/{id}` : r√©sum√©(s), biais, timeline, **cluster_locations**, sources, articles repr√©sentatifs. **‚úÖ Impl√©ment√© (30/09)**
- [ ] `GET /events` : √©v√®nements tri√©s par s√©v√©rit√©/date; filtres: `area_id`, `near=lat,lng&radius`, `country_code`, `category`, `lang`.
- [ ] `GET /search` : recherche mixte avec filtres (langue, source, p√©riode, **category**, **area_id**, bundle).
- [ ] `GET /sources` : catalogue + m√©triques + **cat√©gories** + **couverture g√©o**.
- [ ] `GET /bundles` : listes politiques/th√©matiques et/ou g√©ographiques (ex. *√éle‚Äëde‚ÄëFrance Local*).
- [ ] `POST /user/sources` / `DELETE /user/sources/{id}` : s√©lection/d√©s√©lection de sources.
- [ ] `POST /user/bundles` / `DELETE /user/bundles/{id}` : abonnement bundles.
- [ ] `POST /subscriptions` : `kind` in (`entity`,`topic`,`keyword`,`location`), payload peut r√©f√©rencer `area_id` ou `near`.
- [x] `GET /stream/events` : SSE pour nouveaux √©v√©nements. **‚úÖ Impl√©ment√© (1er/10)**
- [ ] `GET /stream/topics` : SSE pour nouveaux sujets.
- [ ] `GET /health` / `GET /metrics`.

**Contrats** : toujours renvoyer `run_id`, `space_id`, et si applicable une **liste d‚Äôaires g√©o** avec `weight`.

---

## 8) Orchestration des jobs ‚Äî pseudo‚Äëcode

**MVP path (Phase 1)**

- [ ] **ingest(source)** ‚Üí lire **RSS/APIs** ‚Üí nouvelles URLs ‚Üí **extract**
- [ ] **extract(page)** ‚Üí texte + m√©tadonn√©es + entities/places ‚Üí **dedupe**
- [ ] **dedupe(article)** ‚Üí skip si doublon ; sinon **embed**
- [ ] **embed(article)** ‚Üí vecteur (espace actif) ‚Üí **cluster_assign**
- [ ] **cluster_assign(article)** ‚Üí lier cluster (run active) + mettre √† jour `cluster_locations`
- [ ] **cluster_maintain()** (p√©riodique) ‚Üí fusion/scission + labels
- [ ] **summarize(cluster)** ‚Üí dossier EN + locales √† la demande
- [ ] **trend_tick()** ‚Üí `trend_metrics` ‚Üí **event_detect()** (global/local)
- [ ] **notify(event)** ‚Üí r√®gles d‚Äôabonnements ‚Üí push FCM

**Phase 2+ (optionnel)**

- [ ] Ajouter **sitemaps** dans `ingest` et **scrapers cibl√©s** dans `extract`.
- [ ] Phase 3 : introduire **frontier** et t√¢ches `crawl_fetch` d√©di√©es.

---

## 9) Normalisation & d√©doublonnage ‚Äî pseudo‚Äëcode

**canonical_url(url)** : retirer UTM, trier query, normaliser sch√©ma/host/trailing slash, suivre `<link rel=canonical>`.
**extract_text(html)** : boilerplate removal, titre/sous‚Äëtitre, corps, auteurs, date, langue.
**quality_gate(text)** : longueur utile minimale, ratio bruit/texte, encodage OK.
**exact_duplicate?** : `hash_64` √©gal ‚Üí marquer `duplicate_of`.
**near_duplicate?** : `simhash` distance de Hamming ‚â§ 3 dans fen√™tre 72h ‚Üí marquer `near_duplicate_of`.
**route** : si unique ‚Üí continuer pipeline ; sinon, uniquement comptage/statistiques.

---

## 10) Embeddings & stockage ‚Äî pseudo‚Äëcode

- [ ] **Choix fig√©** : **multi‚Äëespaces** (table `article_embeddings_multi` + `embedding_spaces`) pour A/B facile, migrations et coexistence IA locale/cloud.
- [ ] **Politique** : un **espace canonique actif** pour la production; backfill d‚Äôun nouvel espace en **shadow** avant bascule.
- [ ] **Index** : ivfflat (cosine) avec param√©trage probes adapt√© au volume; compression si n√©cessaire.

---

## 11) Clustering en flux ‚Äî pseudo‚Äëcode (versionn√© uniquement)

1. Sur nouveau document ‚Üí voisins kNN dans l‚Äô**espace actif** et la **fen√™tre**.
2. Si `max_cosine ‚â• œÑ` et voisins partagent un cluster dominant (dans **run active**) ‚Üí **assigner**.
3. Sinon ‚Üí **cr√©er** cluster dans `clusters_v` (li√© √† la **run active**).
4. **Job p√©riodique** (par run) : graphe (cosine ‚â• œÑ) ‚Üí communaut√©s (Louvain/Leiden) ‚Üí fusion/scission, mise √† jour labels.
5. Changement d‚Äôalgo/params ‚Üí **nouvelle run** (shadow), puis bascule en `is_active=true`.

---

## 12) R√©sum√© ‚Äúbias breakdown‚Äù ‚Äî logique, langues & **localit√©**

- [ ] **Canonical EN** stock√©, **locales √† la demande** (cache court) pour l‚ÄôUX.
- [ ] **Localit√©** : si `cluster_locations` fortement concentr√© dans un `geo_area`, inclure un **chapeau** (ex.: *√âv√®nement principalement localis√© √† Marseille, FR-13*).
- [ ] **Transparence** : URLs, s√©paration FAITS/ALL√âGATIONS, mention du **p√©rim√®tre g√©o** si pertinent.
- [ ] **Co√ªt** : gating par taille/score/locality.

---

## 13) Recherche ‚Äî Meilisearch

- [ ] Index `articles_search` avec `{ id, title, text_excerpt, lang, source, published_at }`
- [ ] Attributs filtrables: `lang`, `source`
- [ ] Synonymes et stop-words FR/EN
- [ ] Backfill √† l‚Äôingestion + mises √† jour

---

## 14) Temps r√©el (Flutter)

- [x] **SSE** `/stream/events` pour √©v√©nements breaking news. **‚úÖ Impl√©ment√© (1er/10)** avec Redis Pub/Sub
- [ ] **SSE** `/stream/topics` pour nouveaux clusters (l√©ger, compatible mobile)
- [ ] Option **WebSocket** pour commentaires/feedback utilisateur
- [ ] **Cache Redis** pour `/topics` et `/topics/{id}`

---

## 15) Topologie des services (dev/prod) ‚Äî sans code

- [ ] **api** : FastAPI + endpoints + SSE ; d√©pend de Postgres, Redis, Meilisearch ; s‚Äôappuie sur `v_*_active`.
- [ ] **worker** : ex√©cute les jobs Celery (ingest/normalize/embed/cluster/summarize/notify/trends).
- [ ] **beat/scheduler** : planifie t√¢ches p√©riodiques (frontier, tendances, reclustering, compaction index, purge r√©tention).
- [ ] **redis** : broker & backend de t√¢ches.
- [ ] **meilisearch** : moteur plein‚Äëtexte (voir sp√©c ¬ß18bis).
- [ ] **postgres (Supabase manag√©)** : base principale avec pgvector et vues actives.

---

## 16) Observabilit√© & robustesse

- [ ] **Logs** JSON (structlog), **corr√©lation** par `article_id`/`cluster_id`
- [ ] **M√©triques**: taux d‚Äô√©chec par √©tape, latence extraction/LLM, nombre de clusters actifs, co√ªt LLM estim√©
- [ ] **Rate limiting** par domaine (ingestion), **robots.txt** & ToS respect√©s
- [ ] **RGPD**: effacement des donn√©es utilisateur (si comptes), journal d‚Äôacc√®s, minimisation

---

## 17) Plan par √©tapes (MVP ‚Üí Full Feature)

> Organisation concr√®te, **sans code**, avec livrables et crit√®res de sortie.

### √âtape 0 ‚Äî Cadre & environnements

- [ ] **Objectifs** : bases propres, secrets, observabilit√©, politiques de r√©tention (365j).
- [ ] **Livrables** : variables de config document√©es, m√©triques/healthchecks, migrations initiales (tables c≈ìur), jeu de sources seed.
- [ ] **Crit√®res de sortie** : m√©triques expos√©es; DB accessible; quotas LLM d√©sactiv√©s par d√©faut (feature flag).

### √âtape 1 ‚Äî Ingestion Phase 1 (RSS/Atom + APIs)

- [ ] **Objectifs** : polling 50‚Äì200 sources FR/EN, idempotence, qualit√© de flux.
- [ ] **Livrables** : sources remplies (cat√©gories, scope, geo coverage), planification polling, file d‚ÄôURLs.
- [ ] **Crit√®res** : ‚â•50 sources actives; P95 ¬´ flux‚Üíarticle ¬ª ‚â§ 2 min; taux d‚Äôerreur < 2%.

### √âtape 2 ‚Äî Normalisation & d√©doublonnage

- [ ] **Objectifs** : extraction texte fiable, canonisation URL, langue, hash + simhash.
- [ ] **Livrables** : r√®gles qualit√© (longueur utile, bruit), marquage `article_duplicates`.
- [ ] **Crit√®res** : >95% d‚Äôarticles valides; near‚Äëdup d√©tect√©s (hamming ‚â§3) sur reprises d‚Äôagences.

### √âtape 3 ‚Äî Embeddings & similarit√© (espace actif)

- [ ] **Objectifs** : embeddings multilingues, stockage vecteur multi‚Äëespaces, kNN.
- [ ] **Livrables** : `embedding_spaces` (espace canonique), index vectoriel op√©rationnel.
- [ ] **Crit√®res** : requ√™tes kNN < 200 ms p95 sur fen√™tre 48‚Äì72h.

### √âtape 4 ‚Äî Clustering versionn√© (run active)

- [ ] **Objectifs** : assignation en flux, fusion/scission p√©riodiques, labels courts.
- [ ] **Livrables** : `cluster_runs` active, `clusters_v`, `article_cluster_v`, vues `v_*_active`.
- [ ] **Crit√®res** : coh√©rence th√©matique (√©chantillon manuel), taille m√©diane de cluster raisonnable.

### √âtape 5 ‚Äî R√©sum√© & ‚Äúbias breakdown‚Äù

- [ ] **Objectifs** : dossier **canonical EN** (facts vs claims, angles/biais, timeline, sources).
- [ ] **Livrables** : `cluster_summaries_v` (EN), cache pour variantes locales √† la demande.
- [ ] **Crit√®res** : 90% des clusters ¬´ matures ¬ª avec r√©sum√© sous 2 min.

### √âtape 6 ‚Äî Recherche hybride

- [ ] **Objectifs** : plein‚Äëtexte (Meili) + filtres (langue, source, p√©riode, cat√©gorie, zone, bundle).
- [ ] **Livrables** : index minimal align√© sch√©ma; strat√©gie synonyms/stop‚Äëwords FR/EN.
- [ ] **Crit√®res** : latence recherche < 300 ms p95; tol√©rance fautes fonctionnelle.

### √âtape 7 ‚Äî Tendances, √©v√®nements & notifications (push)

- [ ] **Objectifs** : scores volume/velocity/acceleration/novelty/locality; d√©tection global/local; FCM.
- [ ] **Livrables** : `trend_metrics`, `events`, r√®gles minimas; canal `/stream/events`.
- [ ] **Crit√®res** : alerte envoy√©e pour un √©v√®nement test en < 60 s post‚Äëd√©tection; d√©dup OK.

### √âtape 8 ‚Äî API & temps r√©el (SSE)

- [x] **Objectifs** : endpoints `topics`, `topics/{id}`, `events`, `search`, `sources`, `bundles`; flux SSE. **‚úÖ Partiellement (1er/10)**
- [x] **Livrables** : contrats JSON stables (incl. `run_id`, `space_id`). **‚úÖ `/api/v1/topics/{id}` et `/stream/events` op√©rationnels**
- [ ] **Crit√®res** : Flutter affiche liste sujets, fiche sujet (r√©sum√©/biais/timeline/sources), recherche et flux live.

### √âtape 9 ‚Äî Personnalisation (sources, bundles, abonnements)

- [ ] **Objectifs** : s√©lection fine et par **bord politique/th√©matique/g√©o**; subscriptions par entit√©/sujet/mot‚Äëcl√©/zone.
- [ ] **Livrables** : `user_sources`, `user_bundles`, `subscriptions` op√©rationnels.
- [ ] **Crit√®res** : filtres/bundles pilotent effectivement l‚Äôingestion et les notifs.

### √âtape 10 ‚Äî Observabilit√© & SLOs

- [ ] **Objectifs** : tableaux de bord pipeline/co√ªts, alertes techniques, backpressure.
- [ ] **Livrables** : m√©triques cl√©s, budgets LLM, rapports r√©tention.
- [ ] **Crit√®res** : SLOs atteints (voir ¬ß29), runbook incident de base.

**MVP = √âtapes 0 ‚Üí 8 (min) ; 0 ‚Üí 10 (reco).**

---

## 18) Tests & qualit√©

- [ ] **Fixtures** HTML pour extraction; tests dor√©s (golden) de normalisation.
- [ ] Tests unitaires: d√©doublonnage (hash/simhash), kNN pgvector, agr√©gation entit√©s, labellisation biais.
- [ ] Tests E2E: pipeline complet, idempotence, bascule de run (shadow ‚Üí active) sans downtime.
- [ ] Tests performance: quotas crawl, latence assignation cluster, co√ªt/rate des LLM (si activ√©s).

---

## 19) Notes d√©ploiement

- [ ] Docker images s√©par√©es (API vs Worker)
- [ ] Variables d‚Äôenv prod (Supabase, Mistral) via secret manager
- [ ] Auto-migrations Alembic au boot (avec prudence)
- [ ] Strat√©gie de **backfill** initial (batch embeddings + throttling)

---

## 20) Crawl autonome (discovery + frontier)

- [ ] **Seeds**: RSS/sitemaps officiels, pages "derni√®res actus", listes cur√©es.
- [ ] **D√©couverte**: parsing **sitemaps**, liens internes (nofollow respect√©), `<link rel=canonical>`, JSON‚ÄëLD (`extruct`) pour m√©tadonn√©es.
- [ ] **Politeness**: respect **robots.txt** (cache local), `crawl-delay`, user‚Äëagent d√©di√©, **budget par domaine** (req/min, connexions), fen√™tres horaires.
- [ ] **Frontier** (priorit√©): fra√Æcheur source, autorit√©, vitesse de publication pass√©e, nouveaut√© d'URL, p√©nalit√© d'erreurs.
- [ ] **Fetch**: `HEAD` pour filtrer (type/taille), `GET` avec timeouts, d√©tection paywall l√©g√®re, fallback Playwright.
- [ ] **Idempotence**: URL canonique + hash contenu.
- [ ] **Internationalisation**: pr√©f√©rer langue FR/EN mais conserver autres langues si tr√®s corr√©l√© au cluster.
- [ ] **Erreurs**: backoff exponentiel, **DLQ** par type (DNS, 403, 5xx‚Ä¶)

**Tables (extrait)**

```sql
create table crawl_frontier (
  id bigserial primary key,
  url text unique,
  source_id bigint references sources(id),
  priority real default 0,
  last_fetch_at timestamptz,
  fail_count int default 0,
  status text check (status in ('new','enqueued','fetched','blocked','error')) default 'new'
);

create table robots_cache (
  host text primary key,
  fetched_at timestamptz,
  policy text
);
```

**Workers d√©di√©s** : `crawl_discover`, `crawl_fetch`, `extract_links`, puis `normalize`.

**Beat (planification)**

- [ ] t+60s: batch `crawl_frontier` ‚Üí `crawl_fetch` (quota par domaine)
- [ ] t+15m: refresh sitemaps & sources
- [ ] t+15m: reclustering communautaire
- [ ] t+5m: calcul m√©triques de tendance (cf. ¬ß21)

---

## 21) D√©tection d‚Äô√©v√®nements majeurs (bursts & corroboration)

**Objectif** : rep√©rer des pics anormaux et les qualifier **global** vs **local**.

**Pipeline**

1. Comptage 1‚Äì5 min : nouveaux articles/cluster, **sources uniques**, langues, **aire g√©o dominante** (depuis `cluster_locations`).
2. Score `S = w1*volume + w2*velocity + w3*acceleration + w4*novelty + w5*source_diversity + w6*locality`.
3. Seuils **diff√©renci√©s** : `œÑ_global` vs `œÑ_local` (les √©v√®nements tr√®s locaux d√©clenchent √† un volume plus faible si corrobor√©s par ‚â•N sources locales + 1 source tier A si possible).
4. Corroboration : ‚â• N **sources distinctes**; pond√©rer par `trust_tier`.
5. Fusion : si deux clusters explosent et partagent m√™me aire (cosine ‚â• 0.9), fusionner avant alerte.
6. Gating LLM : r√©sum√© ‚Äúbreaking‚Äù seulement si `S >= œÑ_critical`.

---

## 22) Notifications (push/email) & r√®gles

**Canal push** : **Firebase Cloud Messaging (FCM)** pour Flutter (iOS/Android/Web).

**Flux** : `event_detected` ‚Üí `rule_match` ‚Üí `build_payload` ‚Üí `send_fcm` ‚Üí `record_delivery`.

**Tables (extrait)**

```sql
create table user_devices (
  id bigserial primary key,
  user_id uuid not null,
  fcm_token text not null,
  platform text check (platform in ('ios','android','web')) not null,
  created_at timestamptz default now()
);

create table subscriptions (
  id bigserial primary key,
  user_id uuid not null,
  kind text check (kind in ('entity','topic','keyword','location')) not null,
  value text not null,
  lang text,
  min_severity text default 'medium',
  quiet_hours int4range,
  created_at timestamptz default now()
);

create table notifications (
  id bigserial primary key,
  user_id uuid not null,
  event_id bigint references events(id) on delete cascade,
  title text,
  body text,
  sent_at timestamptz,
  dedupe_key text,
  channel text check (channel in ('push','email')) not null,
  status text check (status in ('scheduled','sent','failed')) not null default 'scheduled'
);
create unique index on notifications (user_id, dedupe_key);
```

**R√®gles dynamiques (option)** :

```sql
create table alert_rules (
  id bigserial primary key,
  name text,
  query jsonb,        -- entit√©s/mots-cl√©s/zone
  conditions jsonb,   -- seuils: score, sources uniques, langues
  channels text[] default '{push}',
  is_active boolean default true
);
```

**Bonnes pratiques**

- [ ] **Quiet hours** par utilisateur, time‚Äëzone Europe/Paris.
- [ ] **D√©dup**: ne pas renvoyer plusieurs fois le m√™me √©v√®nement (`dedupe_key`).
- [ ] **Escalade**: r√©p√©ter uniquement si score/severity augmente significativement.

---

## 23) D√©pendances suppl√©mentaires (crawling/√©v√®nements/notifications)

- [ ] SSE c√¥t√© serveur, BeautifulSoup, extruct (JSON‚ÄëLD), orjson.
- [ ] networkx + (optionnel) algos de communaut√©s (python‚Äëlouvain).
- [ ] rapidfuzz (fuzzy matching d‚Äôentit√©s), reppy (robots.txt).
- [ ] firebase‚Äëadmin (FCM), tenacity (retries).
- [ ] Optionnels lourds : hdbscan, scikit‚Äëlearn, PostGIS (si g√©o avanc√©e).

---

## 24) S√©curit√©, l√©galit√©, qualit√©

- [ ] **robots.txt/ToS** stricts, liste de **sources autoris√©es** pr√©f√©rable.
- [ ] Pas d‚Äôextraits longs d‚Äôarticles payants ; conserver les **liens**.
- [ ] **Mod√©ration**: filtrer contenus choquants (mots‚Äëcl√©s, classif simple) avant r√©sum√©.
- [ ] **Transparence**: afficher sources et horodatage UTC + Europe/Paris.
- [ ] **RGPD**: droit √† l‚Äôeffacement (comptes), r√©tention minimale des tokens FCM.

---

## 25) Co√ªts & performances (gating)

- [ ] **Batch embeddings** et cache sur `text_hash`.
- [ ] **Chunking adaptatif**: ne vectoriser que le c≈ìur (lead + 2‚Äì3 paragraphes) pour le clustering; r√©sum√© LLM seulement si **√©v√®nement** ou **cluster mature**.
- [ ] **Backpressure**: stop ingestion si files > seuil; prioriser sources cl√©s.

---

## 26) Scheduler (ex. p√©riodicit√©s ‚Äî sans code)

- [ ] **Chaque minute** : batch `crawl_fetch` par domaine (budgets), monitor frontier.
- [ ] **Toutes les 5 min** : mise √† jour `trend_metrics` + d√©tection d‚Äô√©v√®nements + √©ventuelle notification.
- [ ] **Toutes les 15 min** : reclustering communautaire (par run active) & refresh sitemaps/sources.
- [ ] **Chaque heure** : compaction/optimisation Meilisearch, purge des files anciennes.
- [ ] **Chaque jour** : purge selon r√©tention (cf. ¬ß29), rapports d‚Äôobservabilit√©/co√ªts, rotation √©ventuelle des cl√©s/API.

---

## 27) Principes & choix cl√©s (tech + multilingue)

- [ ] **Architecture versionn√©e** : embeddings multi‚Äëespaces + clustering par "runs" actives ‚áí A/B, rollback, migration IA locale sans casser l‚ÄôAPI.
- [ ] **Ingestion par phases** : MVP = RSS/APIs ‚Üí Phase 2 = sitemaps/scrapers ‚Üí Phase 3 = crawler complet si ROI.
- [ ] **Simplicit√© avant tout** : une seule sortie **canonical EN** stock√©e; variantes locales **√† la demande** (cache court) pour UX et co√ªts ma√Ætris√©s.
- [ ] **KG light** (entit√©s, zones) : indispensable pour filtres, abonnements par entit√©/lieu, et score de **localit√©**.
- [ ] **Recherche hybride** : plein‚Äëtexte (Meili) + s√©mantique (pgvector) pour pertinence et tol√©rance aux fautes.
- [ ] **Transparence & biais** : sources visibles, s√©paration FAITS/ALL√âGATIONS, axes politiques source + biais par article.
- [ ] **Ops** : Celery/Redis (retries, DLQ), SLO clairs, r√©tention 365 jours, SSE pour temps r√©el.

## 29) Sp√©cifications non‚Äëfonctionnelles & **r√©tention**

- [ ] **R√©tention par d√©faut (365 j)** : `raw_html`, `trend_metrics`, logs, notifications; embeddings/clusters conserv√©s jusqu‚Äô√† renouvellement majeur.
- [ ] **SLO ingestion‚Üícluster** : P50 ‚â§ 2 min, P95 ‚â§ 5 min.
- [ ] **SLO √©v√®nement‚Üínotification** : P50 ‚â§ 1 min, P95 ‚â§ 3 min.
- [ ] **Disponibilit√© API** : ‚â• 99.9%/mois.
- [ ] **D√©bit cible** : 50‚Äì100 URLs/min (scalable horizontalement).
- [ ] **Observabilit√©** : m√©triques pipeline/LLM/co√ªts, traces distribu√©es, journaux auditables.

## 30) Structure de fonctionnement (r√©sum√© ex√©cutable)

1. **Ingestion (RSS/APIs)** ‚Üí 2) **Normalize/dedupe** ‚Üí 3) **Embed (espace actif)** ‚Üí 4) **Cluster (run active)** ‚Üí 5) **Summarize EN + locales (cache)** ‚Üí 6) **Trend/Event** ‚Üí 7) **Notify (FCM)** ‚Üí 8) **Serve API/Stream** ‚Üí 9) **Personnaliser & classer (For You / Following / Breaking)**.

---

## 31) Personnalisation par int√©r√™ts (d√©claratif + implicite)

**Objectif** : montrer ce qui **compte** pour l‚Äôutilisateur et **masquer le bruit** ‚Äî sans cr√©er de bulle.

### 31.1 Mod√®le de donn√©es (sch√©mas)

```sql
create table user_interests (
  user_id uuid not null,
  kind text check (kind in ('entity','category','location','source','keyword')) not null,
  value text not null,                 -- id ou slug (ex: 'FR', 'aviation', 'Paris')
  weight real default 1.0,             -- intensit√© d√©clar√©e
  declared boolean default true,       -- vs appris implicitement
  expires_at timestamptz,
  must_include boolean default false,  -- hard-include m√™me si faible engagement
  hard_filter boolean default false,   -- exclure strictement (sauf breaking safety)
  primary key (user_id, kind, value)
);

create table user_feedback (
  user_id uuid not null,
  target_type text check (target_type in ('cluster','article','source')) not null,
  target_id bigint not null,
  signal text check (signal in ('like','hide','dismiss','save','share','open','dwell')) not null,
  value real default 1.0,              -- ex: dwell seconds, like=1, hide=1
  ts timestamptz default now(),
  primary key (user_id, target_type, target_id, signal, ts)
);

create table user_vectors (
  user_id uuid primary key,
  space_id bigint references embedding_spaces(id),
  vector vector(1024),
  updated_at timestamptz default now()
);

create table user_context (
  user_id uuid primary key,
  travelling_area_id bigint,          -- geo_areas.id (opt-in)
  travel_dates daterange,
  relatives_areas bigint[]            -- liste geo_areas.id (opt-in)
);
```

### 31.2 API (ajouts)

- [ ] `GET/POST /user/interests` : g√©rer int√©r√™ts (d√©clar√©s, `must_include`, `hard_filter`, √©ch√©ances).
- [ ] `POST /user/feedback` : like/hide/save/share/open/dwell (agr√©gation c√¥t√© backend).
- [ ] `GET/POST /user/context` : zones de voyage/attaches (opt‚Äëin explicite).
- [ ] Flux : `GET /feed/for-you` (class√©) ; `GET /feed/following` (d√©claratif) ; `GET /feed/breaking` (s√©v√©rit√©).

### 31.3 Politique de ranking (pseudo‚Äëcode)

```
score = w_recency*f(age)
      + w_severity*severity
      + w_declared*match(user_interests, cluster)
      + w_geo*geo_proximity(user_context, cluster_locations)
      + w_personal*sim(user_vector, cluster_vector)
      + w_source*trust_tier(source)
      + w_diversity*novelty(category/political_axis)
      - w_fatigue*repetition(topic)

CONTRAINTES:
- MUST_INCLUDE: garantir n items/24h pour (user_interests.must_include=true) et `subscriptions`.
- HARD_FILTER: exclure sauf si event.severity>=critical OU safety (cat√©gorie "public-safety").
- EXPLORATION: Œµ-greedy/UCB sur un petit pourcentage pour d√©couvrir nouvelles sources/sujets.
- DIVERSIT√â: quotas par cat√©gorie/political_axis pour √©viter la bulle.
```

### 31.4 UX & explications

- [ ] Badges **Pourquoi je vois √ßa ?** (d√©clar√©, proche g√©ographiquement, similaire √† vos likes, breaking).
- [ ] Contr√¥les rapides (Masquer ce sujet, Moins de‚Ä¶, Plus de‚Ä¶)
- [ ] Respect des pr√©f√©rences **d√©claratives** m√™me sans likes (Following ‚â† For You).

### 31.5 Confidentialit√© & conformit√©

- [ ] Contexte (voyages/relatives) **opt‚Äëin** et **√©ditable** ; usage uniquement pour la personnalisation.
- [ ] Export/suppression des signaux (`user_feedback`) via RGPD.

---

## 32) √âvaluation de la personnalisation

**Offline** : NDCG@k, coverage d‚Äôint√©r√™ts d√©clar√©s, diversit√© cat√©gories/axes, taux de masquage ad√©quat.
**Online** : CTR, dwell-time, saves, hide rate, regret (remontr√©e apr√®s hide), satisfaction via feedback.
**Canary** : A/B par `ab_tests`/`ab_buckets`.

---

## 33) Scheduler (MAJ personnalis.)

- [ ] **Toutes les 15 min** : mise √† jour `user_vectors` pour utilisateurs actifs (incr√©mental).
- [ ] **Chaque jour** : d√©cadence des poids implicites, expiration `expires_at`, recalibrage des quotas diversit√©.

---) Structure de fonctionnement (r√©sum√© ex√©cutable)

1. **Crawl/ingest** ‚Üí 2) **Normalize/dedupe** ‚Üí 3) **Embed (espace actif)** ‚Üí 4) **Cluster (run active)** ‚Üí 5) **Summarize EN + locales (cache)** ‚Üí 6) **Trend/Event** ‚Üí 7) **Notify (FCM)** ‚Üí 8) **Serve API/Stream (topics & events)**.

---) Multilingue ‚Äî design & justification

- [ ] **Embeddings multilingues** : permettent le **clustering cross‚Äëlangue** (FR/EN/‚Ä¶ sur un m√™me sujet) sans traduction pr√©alable.
- [ ] **D√©tection de langue** : stock√©e au niveau article; sert √† appliquer stop‚Äëwords, stemming, r√®gles de qualit√© et filtres.
- [ ] **Recherche mixte** : l‚Äôutilisateur peut chercher en FR et retrouver des sources EN via similarit√© s√©mantique (avec label FR).
- [ ] **R√©sum√© cibl√©** : sortie LLM dans la **langue pr√©f√©r√©e** de l‚Äôutilisateur m√™me si sources mixtes; transparence via liste d‚ÄôURLs originales.
- [ ] **NER/G√©ocodage** : mod√®les/lexiques multilingues pour entit√©s; normalisation ISO (personnes, organisations, lieux).
- [ ] **UI/UX** : pr√©f√©rence de langue, choix d‚Äôinclure/exclure langues √©trang√®res, avertissement si la synth√®se s‚Äôappuie majoritairement sur une autre langue.

## 29) Sp√©cifications non‚Äëfonctionnelles (SLO cibles)

- [ ] **Latence ingestion‚Üícluster** : P50 ‚â§ 2 min, P95 ‚â§ 5 min.
- [ ] **Latence √©v√®nement‚Üínotification** : P50 ‚â§ 1 min (apr√®s d√©tection), P95 ‚â§ 3 min.
- [ ] **Disponibilit√© API** : ‚â• 99.9%/mois (hors maintenances planifi√©es).
- [ ] **D√©bit** : 50‚Äì100 URLs/min en vitesse de croisi√®re (scalable horizontalement).
- [ ] **Co√ªts LLM** : budget mensuel born√©; gating (r√©sum√© uniquement pour clusters matures/√©v√®nements).
- [ ] **Conformit√©** : RGPD (donn√©es EU), chiffrement at‚Äërest (Postgres/Redis) et in‚Äëtransit (TLS), rotation secrets.
- [ ] **Observabilit√©** : m√©triques cl√©s (erreurs/latences/co√ªts), traces distribu√©es, journaux auditables.

## 30) Structure de fonctionnement (r√©sum√© ex√©cutable)

1. **Crawl/ingest** ‚Üí 2) **Normalize/dedupe** ‚Üí 3) **Embed** ‚Üí 4) **Cluster** ‚Üí 5) **Summarize/Bias** ‚Üí 6) **Trend/Event** ‚Üí 7) **Notify** ‚Üí 8) **Serve API/Stream**.

---

## 31) Migration vers clustering/processing IA **natif Python** (sans friction)

**Objectif** : pouvoir passer d‚Äôun pipeline IA ‚Äúas‚Äëa‚Äëservice‚Äù (embeddings/r√©sum√©s externes) √† un pipeline **on‚Äëprem/OSS** (embeddings, clustering et r√©sum√© ex√©cut√©s dans vos workers Python) sans casser l‚ÄôAPI ni les donn√©es.

### Principes d‚Äôarchitecture

- [ ] **Ports & Adapters** : d√©finir des interfaces stables (pseudocode) :

  - [ ] `EmbeddingProvider.embed(text) -> vector`
  - [ ] `Clusterer.assign(article_id) -> cluster_id`
  - [ ] `Summarizer.summarize(cluster_id) -> {summary_md, bias_md, timeline_md}`
    Chaque impl√©mentation (Mistral, mod√®le local‚Ä¶) est interchangeable par **feature flag**.
- [ ] **Double √©criture (shadow)** : ex√©cuter un **nouveau provider/clusterer en parall√®le** du courant; ne servir √† l‚Äôapp que la version active.
- [ ] **Contrats de donn√©es versionn√©s** : stocker **espace d‚Äôembedding** et **run de clustering** pour tracer quelle version a produit chaque r√©sultat.
- [ ] **Reproductibilit√©** : journaliser mod√®le, param√®tres, seed, commit git, d√©pendances.

---

## 32) Mod√®le de donn√©es pour le versionnement (embeddings & clustering)

### 32.1 Registre des espaces d‚Äôembedding

```sql
create table embedding_spaces (
  id bigserial primary key,
  name text not null,           -- ex: 'mistral-embed', 'e5-large', 'bge-base'
  provider text not null,       -- 'mistral', 'oss-local', ...
  dims int not null,
  version text,
  notes text,
  created_at timestamptz default now(),
  unique(name, version)
);
```

**Stockage des vecteurs ‚Äî deux strat√©gies**

- [ ] **A. Table par espace** (recommand√©e pour dims vari√©es et index optimaux) :

  - [ ] `article_embeddings_<space_slug>(article_id, embedding vector(<dims>))`
  - [ ] L‚ÄôID de l‚Äôespace est r√©f√©renc√© dans la config; index ivfflat par table.
- [ ] **B. Table unique multi‚Äëespaces** (si dims homog√®nes) :

```sql
create table article_embeddings_multi (
  space_id bigint references embedding_spaces(id),
  article_id bigint references articles(id) on delete cascade,
  embedding vector(1024),
  primary key (space_id, article_id)
);
create index on article_embeddings_multi using ivfflat (embedding vector_cosine_ops);
```

### 32.2 Versionnement du clustering

```sql
create table cluster_runs (
  id bigserial primary key,
  space_id bigint references embedding_spaces(id),
  algo text not null,                 -- 'threshold+communities', 'hdbscan', ...
  params jsonb not null,              -- œÑ, fen√™tre, k, etc.
  started_at timestamptz default now(),
  finished_at timestamptz,
  status text check (status in ('running','complete','failed')),
  is_active boolean default false,
  notes text
);

create table clusters_v (
  id bigserial primary key,
  run_id bigint references cluster_runs(id) on delete cascade,
  label text,
  window_start timestamptz,
  window_end timestamptz,
  created_at timestamptz default now()
);

create table article_cluster_v (
  run_id bigint references cluster_runs(id) on delete cascade,
  cluster_id bigint references clusters_v(id) on delete cascade,
  article_id bigint references articles(id) on delete cascade,
  similarity real,
  primary key (run_id, cluster_id, article_id)
);

-- Vue pour exposer la "run" active sans changer l'API
create view v_clusters_active as
  select c.* from clusters_v c join cluster_runs r on r.id=c.run_id where r.is_active;
create view v_article_cluster_active as
  select ac.* from article_cluster_v ac join cluster_runs r on r.id=ac.run_id where r.is_active;
```

### 32.3 Versionnement des r√©sum√©s

```sql
create table cluster_summaries_v (
  run_id bigint references cluster_runs(id) on delete cascade,
  cluster_id bigint references clusters_v(id) on delete cascade,
  engine text not null,            -- 'mistral', 'local-llm'
  engine_version text,
  summary_md text,
  bias_md text,
  timeline_md text,
  sources jsonb,
  created_at timestamptz default now(),
  primary key (run_id, cluster_id, engine, engine_version)
);
```

---

## 33) Strat√©gie de migration (√©tapes s√ªres)

1. **Pr√©parer les registres** : cr√©er `embedding_spaces`, `cluster_runs`, tables versionn√©es `*_v` & vues `v_*_active`.
2. **Backfill embeddings** pour le **nouvel espace** (batch + quotas) sans impacter l‚ÄôAPI.
3. **Lancer un cluster_run (shadow)** sur le nouvel espace ‚Üí remplir `clusters_v`/`article_cluster_v`.
4. **G√©n√©rer r√©sum√©s** en parall√®le dans `cluster_summaries_v` avec `engine='local-llm'` (ou rester sur Mistral si seul le clustering change).
5. **√âvaluer** (voir ¬ß34) sur un corpus t√©moin; ajuster œÑ/params.
6. **Canary** : marquer `is_active=true` sur le nouveau `run_id` pour **X% des utilisateurs** (via un flag c√¥t√© API).
7. **Basculer** : set `is_active=true` pour tous; conserver l‚Äôancienne run N jours pour rollback.
8. **Nettoyage** : purge progressive des embeddings obsol√®tes si co√ªts de stockage.

---

## 34) √âvaluation & qualit√© (offline + online)

**Offline**

- [ ] **Topic coherence** (PMI/NPMI), **purity** (si labels dispos), taille moyenne des clusters, ratio near‚Äëdup.
- [ ] **Cross‚Äëlingual recall** : proportion d‚Äôarticles d‚Äôautres langues rattach√©s correctement.
- [ ] **Stabilit√©** : taux de remappage d‚Äôarticles entre runs successifs.

**Online**

- [ ] **CTR** sur notifications, **dwell time** par sujet, **feedback utile/biais**.
- [ ] **A/B** : table `ab_tests(user_id, run_id, bucket, started_at, ended_at)`.

**Jeu de v√©rit√©** (option)

- [ ] Panel interne + guidelines d‚Äôannotation (m√™mes sujets / pas m√™mes sujets, biais per√ßu, exhaustivit√©).

---

## 35) Sp√©cificit√©s infra pour IA native

- [ ] **Workers GPU d√©di√©s** (queue `gpu`) pour embeddings/r√©sum√©s locaux; batch & quantization pour r√©duire co√ªt/latence.
- [ ] **Limiteurs** : plafond QPS/TPM par mod√®le; backpressure sur files.
- [ ] **Cache de features** : ne recalculer un embedding que si `text_hash` change.
- [ ] **Observabilit√© IA** : temps/token, m√©moire GPU, taux d‚Äôerreur mod√®le.
- [ ] **S√©curit√©** : sandbox pour ex√©cutables tiers, revue des licences mod√®les/datasets.
